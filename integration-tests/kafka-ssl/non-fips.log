[INFO] Scanning for projects...
[INFO]
[INFO] --< org.apache.camel.quarkus:camel-quarkus-integration-test-kafka-ssl >--
[INFO] Building Camel Quarkus :: Integration Tests :: Kafka SSL 3.11.0-SNAPSHOT
[INFO]   from pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO]
[INFO] --- clean:3.2.0:clean (default-clean) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Deleting /home/jondruse/git/community/camel-quarkus/integration-tests/kafka-ssl/target
[INFO]
[INFO] --- enforcer:3.0.0-M3:enforce (enforce-java-version) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO]
[INFO] --- enforcer:3.0.0-M3:enforce (camel-quarkus-enforcer-rules) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO]
[INFO] --- gplus:3.0.0:execute (sanity-checks) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Using plugin classloader, includes GMavenPlus and project classpath.
[INFO] Using Groovy 4.0.21 to perform execute.
[INFO] Running Groovy script from file:/home/jondruse/git/community/camel-quarkus/tooling/scripts/sanity-checks.groovy.
[INFO]
[INFO] --- formatter:2.23.0:format (format) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Processed 5 files in 1s7ms (Formatted: 0, Skipped: 0, Unchanged: 5, Failed: 0, Readonly: 0)
[INFO]
[INFO] --- impsort:1.9.0:sort (sort-imports) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Processed 5 files in 00:00.151 (Already Sorted: 5, Needed Sorting: 0)
[INFO]
[INFO] --- resources:3.3.1:resources (default-resources) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Copying 1 resource from src/main/resources to target/classes
[INFO]
[INFO] --- compiler:3.11.0:compile (default-compile) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Changes detected - recompiling the module! :source
[INFO] Compiling 2 source files with javac [debug deprecation release 17] to target/classes
[INFO]
[INFO] --- resources:3.3.1:testResources (default-testResources) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Copying 3 resources from src/test/resources to target/test-classes
[INFO]
[INFO] --- compiler:3.11.0:testCompile (default-testCompile) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Changes detected - recompiling the module! :dependency
[INFO] Compiling 3 source files with javac [debug deprecation release 17] to target/test-classes
[INFO]
[INFO] --- gplus:3.0.0:execute (generate-test-container-config) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Using plugin classloader, includes GMavenPlus and project classpath.
[INFO] Using Groovy 4.0.21 to perform execute.
[INFO] Running Groovy script from file:/home/jondruse/git/community/camel-quarkus/tooling/scripts/generate-test-containers-config-properties.groovy.
[INFO]
[INFO] --- surefire:3.1.2:test (default-test) @ camel-quarkus-integration-test-kafka-ssl ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO]
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.camel.quarkus.kafka.ssl.KafkaSslTest
2024-05-10 11:33:59,983 WARN  [io.qua.arc.pro.Methods] (build-62) JDK class java.util.Hashtable with final method cloneHashtable() cannot be proxied and is not transformable. This method will be ignored during proxy generation and should never be invoked upon the proxy instance!
2024-05-10 11:33:59,991 WARN  [io.qua.arc.pro.Methods] (build-62) JDK class java.util.Hashtable with final method defaultWriteHashtable() cannot be proxied and is not transformable. This method will be ignored during proxy generation and should never be invoked upon the proxy instance!
2024-05-10 11:33:59,985 WARN  [io.qua.arc.pro.Methods] (build-26) JDK class java.util.Hashtable with final method cloneHashtable() cannot be proxied and is not transformable. This method will be ignored during proxy generation and should never be invoked upon the proxy instance!
2024-05-10 11:33:59,994 WARN  [io.qua.arc.pro.Methods] (build-26) JDK class java.util.Hashtable with final method defaultWriteHashtable() cannot be proxied and is not transformable. This method will be ignored during proxy generation and should never be invoked upon the proxy instance!
2024-05-10 11:34:00,413 INFO  [org.tes.doc.DockerClientProviderStrategy] (pool-3-thread-1) Loaded org.testcontainers.dockerclient.RootlessDockerClientProviderStrategy from ~/.testcontainers.properties, will try it first
2024-05-10 11:34:00,599 INFO  [org.tes.doc.DockerClientProviderStrategy] (pool-3-thread-1) Found Docker environment with Rootless Docker accessed via Unix socket (/run/user/1000/docker.sock)
2024-05-10 11:34:00,606 INFO  [org.tes.ima.PullPolicy] (pool-3-thread-1) Image pull policy will be performed by: DefaultPullPolicy()
2024-05-10 11:34:00,607 INFO  [org.tes.uti.ImageNameSubstitutor] (pool-3-thread-1) Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
2024-05-10 11:34:00,611 INFO  [org.tes.DockerClientFactory] (pool-3-thread-1) Docker host IP address is localhost
2024-05-10 11:34:00,638 INFO  [org.tes.DockerClientFactory] (pool-3-thread-1) Connected to docker:
  Server Version: 24.0.2
  API Version: 1.43
  Operating System: Fedora Linux 36 (Thirty Six)
  Total Memory: 31838 MB
2024-05-10 11:34:00,664 INFO  [tc.tes.6.0] (pool-3-thread-1) Creating container for image: testcontainers/ryuk:0.6.0
2024-05-10 11:34:00,747 INFO  [tc.tes.6.0] (pool-3-thread-1) Container testcontainers/ryuk:0.6.0 is starting: 45cf5a653878ba0804c60d4efbed7b4f57b3daa5aeed6edad7aba93e341e0e99
2024-05-10 11:34:01,032 INFO  [tc.tes.6.0] (pool-3-thread-1) Container testcontainers/ryuk:0.6.0 started in PT0.367758555S
2024-05-10 11:34:01,036 INFO  [org.tes.uti.RyukResourceReaper] (pool-3-thread-1) Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
2024-05-10 11:34:01,036 INFO  [org.tes.DockerClientFactory] (pool-3-thread-1) Checking the system...
2024-05-10 11:34:01,037 INFO  [org.tes.DockerClientFactory] (pool-3-thread-1) ✔︎ Docker server version should be at least 1.6.0
2024-05-10 11:34:01,037 INFO  [tc.eclipse-temurin:17-jdk] (pool-3-thread-1) Creating container for image: eclipse-temurin:17-jdk
2024-05-10 11:34:01,055 INFO  [tc.eclipse-temurin:17-jdk] (pool-3-thread-1) Container eclipse-temurin:17-jdk is starting: 7ef4d8acd8ea2975f7b8a18b6065ca7d24d891341303e0cced3ab2a4a6b673b2
2024-05-10 11:34:01,240 INFO  [tc.eclipse-temurin:17-jdk] (pool-3-thread-1) Container eclipse-temurin:17-jdk started in PT0.202501341S
2024-05-10 11:34:02,574 INFO  [tc.qua.io/.2.1] (pool-3-thread-1) Creating container for image: quay.io/strimzi-test-container/test-container:latest-kafka-3.2.1
2024-05-10 11:34:02,692 INFO  [tc.qua.io/.2.1] (pool-3-thread-1) Container quay.io/strimzi-test-container/test-container:latest-kafka-3.2.1 is starting: edc46e2aa962d25d594b6825c70d6800290e00b53ed68288a09b0a3b9b77f855
2024-05-10 11:34:02,902 INFO  [io.str.tes.con.StrimziKafkaContainer] (pool-3-thread-1) Mapped port: 32805
2024-05-10 11:34:02,902 INFO  [io.str.tes.con.StrimziKafkaContainer] (pool-3-thread-1) This is all advertised listeners for Kafka SSL://localhost:32805,BROKER1://192.168.32.2:9093
2024-05-10 11:34:02,903 INFO  [io.str.tes.con.StrimziKafkaContainer] (pool-3-thread-1) Copying command to 'STARTER_SCRIPT' script.
[2024-05-10 09:34:03,811] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,813] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,818] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,818] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,818] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,820] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,822] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-05-10 09:34:03,823] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-05-10 09:34:03,823] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-05-10 09:34:03,823] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-05-10 09:34:03,824] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-05-10 09:34:03,825] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,825] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,826] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,826] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,826] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,826] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-05-10 09:34:03,826] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-05-10 09:34:03,837] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@53ca01a2 (org.apache.zookeeper.server.ServerMetrics)
[2024-05-10 09:34:03,840] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-05-10 09:34:03,847] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-05-10 09:34:03,851] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,851] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,853] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,853] INFO Server environment:host.name=edc46e2aa962 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,853] INFO Server environment:java.version=11.0.16 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,853] INFO Server environment:java.vendor=Red Hat, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,853] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-11.0.16.0.8-1.el8_6.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,853] INFO Server environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-3.2.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-3.2.1.jar:/opt/kafka/bin/../libs/connect-json-3.2.1.jar:/opt/kafka/bin/../libs/connect-mirror-3.2.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-3.2.1.jar:/opt/kafka/bin/../libs/connect-runtime-3.2.1.jar:/opt/kafka/bin/../libs/connect-transforms-3.2.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.12.6.jar:/opt/kafka/bin/../libs/jackson-core-2.12.6.jar:/opt/kafka/bin/../libs/jackson-databind-2.12.6.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.12.6.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.12.6.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.12.6.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.6.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.6.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.12.6.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-http-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-io-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-security-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-server-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-util-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jline-3.21.0.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/jose4j-0.7.9.jar:/opt/kafka/bin/../libs/kafka-clients-3.2.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-3.2.1.jar:/opt/kafka/bin/../libs/kafka-metadata-3.2.1.jar:/opt/kafka/bin/../libs/kafka-raft-3.2.1.jar:/opt/kafka/bin/../libs/kafka-server-common-3.2.1.jar:/opt/kafka/bin/../libs/kafka-shell-3.2.1.jar:/opt/kafka/bin/../libs/kafka-storage-3.2.1.jar:/opt/kafka/bin/../libs/kafka-storage-api-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-3.2.1.jar:/opt/kafka/bin/../libs/kafka-tools-3.2.1.jar:/opt/kafka/bin/../libs/kafka_2.13-3.2.1.jar:/opt/kafka/bin/../libs/lz4-java-1.8.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.4.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-tcnative-classes-2.0.46.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-transport-classes-epoll-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.73.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.3.0.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/reload4j-1.2.19.jar:/opt/kafka/bin/../libs/rocksdbjni-6.29.4.1.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/opt/kafka/bin/../libs/scala-library-2.13.8.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.8.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.36.jar:/opt/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/opt/kafka/bin/../libs/trogdor-3.2.1.jar:/opt/kafka/bin/../libs/zookeeper-3.6.3.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/opt/kafka/bin/../libs/zstd-jni-1.5.2-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,853] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:os.version=6.2.15-100.fc36.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:user.name=strimzi (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:user.home=/home/strimzi (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:user.dir=/opt/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:os.memory.free=491MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,854] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,855] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,855] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,855] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,855] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,855] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,855] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,855] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,857] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-05-10 09:34:03,859] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,859] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,860] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-05-10 09:34:03,860] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-05-10 09:34:03,861] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-05-10 09:34:03,862] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-05-10 09:34:03,862] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-05-10 09:34:03,862] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-05-10 09:34:03,862] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-05-10 09:34:03,862] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-05-10 09:34:03,866] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,866] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,866] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,872] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-05-10 09:34:03,873] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-05-10 09:34:03,875] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-05-10 09:34:03,879] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-05-10 09:34:03,891] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-05-10 09:34:03,892] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-05-10 09:34:03,893] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-05-10 09:34:03,893] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-05-10 09:34:03,898] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-05-10 09:34:03,899] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-05-10 09:34:03,901] INFO Snapshot loaded in 8 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2024-05-10 09:34:03,902] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-05-10 09:34:03,903] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-05-10 09:34:03,918] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-05-10 09:34:03,919] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2024-05-10 09:34:03,935] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-05-10 09:34:03,936] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-05-10 09:34:04,105] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-05-10 09:34:04,181] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-05-10 09:34:04,184] INFO starting (kafka.server.KafkaServer)
[2024-05-10 09:34:04,185] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-05-10 09:34:04,195] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-05-10 09:34:04,199] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,199] INFO Client environment:host.name=edc46e2aa962 (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,199] INFO Client environment:java.version=11.0.16 (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,199] INFO Client environment:java.vendor=Red Hat, Inc. (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-11.0.16.0.8-1.el8_6.x86_64 (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-3.2.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-3.2.1.jar:/opt/kafka/bin/../libs/connect-json-3.2.1.jar:/opt/kafka/bin/../libs/connect-mirror-3.2.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-3.2.1.jar:/opt/kafka/bin/../libs/connect-runtime-3.2.1.jar:/opt/kafka/bin/../libs/connect-transforms-3.2.1.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.12.6.jar:/opt/kafka/bin/../libs/jackson-core-2.12.6.jar:/opt/kafka/bin/../libs/jackson-databind-2.12.6.1.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.12.6.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.12.6.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.12.6.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.12.6.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.12.6.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.12.6.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.34.jar:/opt/kafka/bin/../libs/jersey-common-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/kafka/bin/../libs/jersey-server-2.34.jar:/opt/kafka/bin/../libs/jetty-client-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-http-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-io-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-security-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-server-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-util-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.44.v20210927.jar:/opt/kafka/bin/../libs/jline-3.21.0.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/jose4j-0.7.9.jar:/opt/kafka/bin/../libs/kafka-clients-3.2.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-3.2.1.jar:/opt/kafka/bin/../libs/kafka-metadata-3.2.1.jar:/opt/kafka/bin/../libs/kafka-raft-3.2.1.jar:/opt/kafka/bin/../libs/kafka-server-common-3.2.1.jar:/opt/kafka/bin/../libs/kafka-shell-3.2.1.jar:/opt/kafka/bin/../libs/kafka-storage-3.2.1.jar:/opt/kafka/bin/../libs/kafka-storage-api-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-3.2.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-3.2.1.jar:/opt/kafka/bin/../libs/kafka-tools-3.2.1.jar:/opt/kafka/bin/../libs/kafka_2.13-3.2.1.jar:/opt/kafka/bin/../libs/lz4-java-1.8.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.8.4.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-tcnative-classes-2.0.46.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-transport-classes-epoll-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.73.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.73.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.3.0.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/reload4j-1.2.19.jar:/opt/kafka/bin/../libs/rocksdbjni-6.29.4.1.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.6.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/opt/kafka/bin/../libs/scala-library-2.13.8.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.8.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.36.jar:/opt/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/opt/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/opt/kafka/bin/../libs/trogdor-3.2.1.jar:/opt/kafka/bin/../libs/zookeeper-3.6.3.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/opt/kafka/bin/../libs/zstd-jni-1.5.2-1.jar (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:os.version=6.2.15-100.fc36.x86_64 (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:user.name=strimzi (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:user.home=/home/strimzi (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,200] INFO Client environment:user.dir=/opt/kafka (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,201] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,201] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,201] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,203] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@16aa8654 (org.apache.zookeeper.ZooKeeper)
[2024-05-10 09:34:04,216] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-05-10 09:34:04,220] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-05-10 09:34:04,223] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-05-10 09:34:04,223] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-05-10 09:34:04,227] INFO Socket connection established, initiating session, client: /127.0.0.1:38708, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-05-10 09:34:04,238] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-05-10 09:34:04,251] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000a1e34e0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-05-10 09:34:04,254] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-05-10 09:34:04,353] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-05-10 09:34:04,363] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2024-05-10 09:34:04,363] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2024-05-10 09:34:04,476] INFO Cluster ID = SwD2YEpfQhGKEXxAogmkrg (kafka.server.KafkaServer)
[2024-05-10 09:34:04,478] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2024-05-10 09:34:04,513] INFO KafkaConfig values:
	advertised.listeners = SSL://localhost:32805,BROKER1://192.168.32.2:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = BROKER1
	inter.broker.protocol.version = 3.2-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,BROKER1:PLAINTEXT
	listeners = BROKER1://0.0.0.0:9093,SSL://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm =
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /etc/kafka/secrets/kafka-keystore.p12
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /etc/kafka/secrets/kafka-truststore.p12
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-05-10 09:34:04,561] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-05-10 09:34:04,562] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-05-10 09:34:04,563] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-05-10 09:34:04,564] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-05-10 09:34:04,579] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2024-05-10 09:34:04,596] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2024-05-10 09:34:04,598] INFO Attempting recovery for all logs in /tmp/kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-05-10 09:34:04,602] INFO Loaded 0 logs in 6ms. (kafka.log.LogManager)
[2024-05-10 09:34:04,603] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-05-10 09:34:04,605] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-05-10 09:34:04,847] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2024-05-10 09:34:04,981] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-05-10 09:34:04,983] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2024-05-10 09:34:05,007] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(BROKER1) (kafka.network.SocketServer)
[2024-05-10 09:34:05,008] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-05-10 09:34:05,008] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-05-10 09:34:05,239] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(SSL) (kafka.network.SocketServer)
[2024-05-10 09:34:05,247] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
[2024-05-10 09:34:05,265] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,266] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,267] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,267] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,281] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-05-10 09:34:05,300] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-05-10 09:34:05,318] INFO Stat of the created znode at /brokers/ids/1 is: 25,25,1715333645309,1715333645309,1,0,0,72058289341202432,240,0,25
 (kafka.zk.KafkaZkClient)
[2024-05-10 09:34:05,319] INFO Registered broker 1 at path /brokers/ids/1 with addresses: SSL://localhost:32805,BROKER1://192.168.32.2:9093, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2024-05-10 09:34:05,366] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,371] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,371] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,375] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2024-05-10 09:34:05,387] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:05,390] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2024-05-10 09:34:05,393] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:05,418] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-05-10 09:34:05,422] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2024-05-10 09:34:05,423] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-05-10 09:34:05,423] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-05-10 09:34:05,456] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-05-10 09:34:05,477] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-05-10 09:34:05,487] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2024-05-10 09:34:05,493] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(BROKER1) (kafka.network.SocketServer)
[2024-05-10 09:34:05,496] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(SSL) (kafka.network.SocketServer)
[2024-05-10 09:34:05,497] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2024-05-10 09:34:05,502] INFO Kafka version: 3.2.1 (org.apache.kafka.common.utils.AppInfoParser)
[2024-05-10 09:34:05,502] INFO Kafka commitId: b172a0a94f4ebb9f (org.apache.kafka.common.utils.AppInfoParser)
[2024-05-10 09:34:05,502] INFO Kafka startTimeMs: 1715333645497 (org.apache.kafka.common.utils.AppInfoParser)
[2024-05-10 09:34:05,504] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2024-05-10 09:34:05,549] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use broker 192.168.32.2:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2024-05-10 11:34:05,550 INFO  [tc.qua.io/.2.1] (pool-3-thread-1) Container quay.io/strimzi-test-container/test-container:latest-kafka-3.2.1 started in PT2.976511022S
[2024-05-10 09:34:05,556] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker 192.168.32.2:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
2024-05-10 11:34:06,158 INFO  [org.apa.cam.qua.cor.CamelBootstrapRecorder] (main) Bootstrap runtime: org.apache.camel.quarkus.main.CamelMainRuntime
2024-05-10 11:34:06,159 INFO  [org.apa.cam.mai.MainSupport] (main) Apache Camel (Main) 4.5.0 is starting
2024-05-10 11:34:06,201 INFO  [org.apa.cam.mai.BaseMainSupport] (main) Auto-configuration summary
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.sslKeystoreType=PKCS12
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.sslKeystoreLocation=/tmp/KafkaSaslSslTestResource-2303763757013114977/kafka-keystore.p12
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.sslTruststoreType=PKCS12
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.securityProtocol=SSL
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.sslTruststorePassword=xxxxxx
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.sslKeyPassword=xxxxxx
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.sslKeystorePassword=xxxxxx
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.sslTruststoreLocation=/tmp/KafkaSaslSslTestResource-2303763757013114977/kafka-truststore.p12
2024-05-10 11:34:06,202 INFO  [org.apa.cam.mai.BaseMainSupport] (main)     [MicroProfilePropertiesSource] camel.component.kafka.brokers=SSL://localhost:32805
2024-05-10 11:34:06,269 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.5.0 (camel-1) is starting
2024-05-10 11:34:06,590 INFO  [org.apa.cam.com.kaf.KafkaConsumer] (main) Starting Kafka consumer on topic: inbound with breakOnFirstError: false
2024-05-10 11:34:06,602 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Routes startup (total:1)
2024-05-10 11:34:06,603 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main)     Started route1 (kafka://inbound)
2024-05-10 11:34:06,603 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.5.0 (camel-1) started in 333ms (build:0ms init:0ms start:333ms)
2024-05-10 11:34:06,603 INFO  [org.apa.cam.com.kaf.KafkaFetchRecords] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) Connecting Kafka consumer thread ID inbound-Thread 0 with poll timeout of 5000 ms
2024-05-10 11:34:06,713 INFO  [io.quarkus] (main) camel-quarkus-integration-test-kafka-ssl 3.11.0-SNAPSHOT on JVM (powered by Quarkus 3.10.0) started in 8.825s. Listening on: http://localhost:8081
2024-05-10 11:34:06,714 INFO  [io.quarkus] (main) Profile test activated.
2024-05-10 11:34:06,714 INFO  [io.quarkus] (main) Installed features: [camel-core, camel-kafka, camel-log, cdi, kafka-client, resteasy, resteasy-jsonb, smallrye-context-propagation, vertx]
2024-05-10 11:34:06,736 INFO  [org.apa.cam.com.kaf.con.sup.cla.AssignmentAdapterHelper] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) Using NO-OP resume strategy
2024-05-10 11:34:06,736 INFO  [org.apa.cam.com.kaf.KafkaFetchRecords] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) Subscribing inbound-Thread 0 to topic inbound
[2024-05-10 09:34:07,206] INFO Creating topic inbound with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2024-05-10 11:34:07,235 WARN  [org.apa.kaf.cli.NetworkClient] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) [Consumer clientId=consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1, groupId=eac2dbb5-4d9b-4b91-9440-bd5958eea6aa] Error while fetching metadata with correlation id 2 : {inbound=LEADER_NOT_AVAILABLE}
[2024-05-10 09:34:07,245] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1), 1 -> ArrayBuffer(1), 2 -> ArrayBuffer(1), 3 -> ArrayBuffer(1), 4 -> ArrayBuffer(1), 5 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 7 -> ArrayBuffer(1), 8 -> ArrayBuffer(1), 9 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 11 -> ArrayBuffer(1), 12 -> ArrayBuffer(1), 13 -> ArrayBuffer(1), 14 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 16 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 19 -> ArrayBuffer(1), 20 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 23 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 25 -> ArrayBuffer(1), 26 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 28 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 31 -> ArrayBuffer(1), 32 -> ArrayBuffer(1), 33 -> ArrayBuffer(1), 34 -> ArrayBuffer(1), 35 -> ArrayBuffer(1), 36 -> ArrayBuffer(1), 37 -> ArrayBuffer(1), 38 -> ArrayBuffer(1), 39 -> ArrayBuffer(1), 40 -> ArrayBuffer(1), 41 -> ArrayBuffer(1), 42 -> ArrayBuffer(1), 43 -> ArrayBuffer(1), 44 -> ArrayBuffer(1), 45 -> ArrayBuffer(1), 46 -> ArrayBuffer(1), 47 -> ArrayBuffer(1), 48 -> ArrayBuffer(1), 49 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2024-05-10 09:34:07,325] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(inbound-0) (kafka.server.ReplicaFetcherManager)
[2024-05-10 09:34:07,469] INFO [LogLoader partition=inbound-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
2024-05-10 11:34:07,476 WARN  [org.apa.kaf.cli.NetworkClient] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) [Consumer clientId=consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1, groupId=eac2dbb5-4d9b-4b91-9440-bd5958eea6aa] Error while fetching metadata with correlation id 5 : {inbound=LEADER_NOT_AVAILABLE}
[2024-05-10 09:34:07,491] INFO Created log for partition inbound-0 in /tmp/kafka-logs/inbound-0 with properties {} (kafka.log.LogManager)
[2024-05-10 09:34:07,493] INFO [Partition inbound-0 broker=1] No checkpointed highwatermark is found for partition inbound-0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,494] INFO [Partition inbound-0 broker=1] Log loaded for partition inbound-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,550] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2024-05-10 09:34:07,568] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,570] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,573] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2024-05-10 09:34:07,573] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,583] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,584] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,585] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2024-05-10 09:34:07,586] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,597] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,601] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,602] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2024-05-10 09:34:07,603] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,616] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,617] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,620] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2024-05-10 09:34:07,621] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,632] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,633] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,634] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2024-05-10 09:34:07,635] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,646] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,647] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,649] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2024-05-10 09:34:07,649] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,661] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,663] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,668] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2024-05-10 09:34:07,669] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,679] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,680] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,681] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2024-05-10 09:34:07,682] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,693] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,694] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,696] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2024-05-10 09:34:07,697] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,709] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,711] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,712] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2024-05-10 09:34:07,712] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,724] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,725] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,727] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2024-05-10 09:34:07,728] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,746] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,748] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,752] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2024-05-10 09:34:07,753] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,766] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,767] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,768] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2024-05-10 09:34:07,768] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,780] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,781] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,782] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2024-05-10 09:34:07,782] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,794] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,795] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,797] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2024-05-10 09:34:07,797] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,811] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,813] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,814] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2024-05-10 09:34:07,814] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,824] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,825] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,826] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2024-05-10 09:34:07,827] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,837] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,838] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,839] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2024-05-10 09:34:07,839] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,849] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,850] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,852] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2024-05-10 09:34:07,853] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,865] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,866] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,868] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2024-05-10 09:34:07,868] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,879] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,880] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,881] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2024-05-10 09:34:07,882] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,893] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,894] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,896] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2024-05-10 09:34:07,897] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,908] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,909] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,912] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2024-05-10 09:34:07,912] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,925] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,926] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,928] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2024-05-10 09:34:07,928] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,939] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,941] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,942] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2024-05-10 09:34:07,943] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,956] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,957] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,959] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2024-05-10 09:34:07,959] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,973] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,975] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,976] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2024-05-10 09:34:07,977] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:07,990] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:07,991] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:07,993] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2024-05-10 09:34:07,993] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,006] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,007] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,009] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2024-05-10 09:34:08,009] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,019] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,019] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,021] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2024-05-10 09:34:08,021] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,031] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,032] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,034] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2024-05-10 09:34:08,035] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,050] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,051] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,051] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2024-05-10 09:34:08,052] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,070] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,072] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,073] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2024-05-10 09:34:08,073] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,088] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,089] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,090] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2024-05-10 09:34:08,090] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,106] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,118] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,122] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2024-05-10 09:34:08,122] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,138] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,139] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,141] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2024-05-10 09:34:08,142] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,160] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,162] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,164] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2024-05-10 09:34:08,164] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,182] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,183] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,186] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,186] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,203] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,205] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,206] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2024-05-10 09:34:08,206] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,222] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,224] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,226] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2024-05-10 09:34:08,227] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,241] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,242] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,244] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2024-05-10 09:34:08,244] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,258] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,259] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,259] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2024-05-10 09:34:08,260] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,272] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,273] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,275] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2024-05-10 09:34:08,275] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,285] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,286] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,288] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2024-05-10 09:34:08,288] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,304] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,306] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,306] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2024-05-10 09:34:08,306] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,321] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,322] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,324] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2024-05-10 09:34:08,324] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,337] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,338] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,341] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2024-05-10 09:34:08,343] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,354] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,356] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,357] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2024-05-10 09:34:08,358] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,369] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,370] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,373] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2024-05-10 09:34:08,373] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,383] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,384] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-05-10 09:34:08,386] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2024-05-10 09:34:08,386] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,392] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,393] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,395] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,395] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,396] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,396] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,396] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,396] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,396] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,396] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,396] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,396] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,398] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,398] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,398] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,398] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,398] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,398] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,398] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,398] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,398] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,398] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,399] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,399] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,399] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,399] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,399] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,399] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,399] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,399] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,399] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,399] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,400] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,400] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,400] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,400] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,400] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,400] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,400] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,400] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,400] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,401] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,401] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,401] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,401] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,401] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,401] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,401] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,402] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,402] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,402] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,402] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,402] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,402] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,402] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,402] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,402] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,402] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,402] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 7 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,403] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,403] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,403] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,403] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,403] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,403] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,403] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,403] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,403] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,403] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,403] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,404] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,405] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,406] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,406] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,407] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,407] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,407] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,408] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,408] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,408] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,409] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,409] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,409] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,409] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,409] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,411] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,411] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,411] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,411] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,411] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,412] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,412] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,412] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,412] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,412] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,413] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,413] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,413] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,413] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,413] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,414] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,414] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,414] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,414] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,415] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,415] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-05-10 09:34:08,510] INFO Creating topic outbound with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
2024-05-10 11:34:08,524 WARN  [org.apa.kaf.cli.NetworkClient] (executor-thread-1) [Consumer clientId=consumer-camel-quarkus-group-2, groupId=camel-quarkus-group] Error while fetching metadata with correlation id 2 : {outbound=LEADER_NOT_AVAILABLE}
[2024-05-10 09:34:08,541] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(outbound-0) (kafka.server.ReplicaFetcherManager)
[2024-05-10 09:34:08,555] INFO [LogLoader partition=outbound-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-05-10 09:34:08,556] INFO Created log for partition outbound-0 in /tmp/kafka-logs/outbound-0 with properties {} (kafka.log.LogManager)
[2024-05-10 09:34:08,561] INFO [Partition outbound-0 broker=1] No checkpointed highwatermark is found for partition outbound-0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,562] INFO [Partition outbound-0 broker=1] Log loaded for partition outbound-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-05-10 09:34:08,578] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group camel-quarkus-group in Empty state. Created a new member id consumer-camel-quarkus-group-2-fbbb9fda-dc9f-44c4-b438-ef9ca5df34b0 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,594] INFO [GroupCoordinator 1]: Preparing to rebalance group camel-quarkus-group in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member consumer-camel-quarkus-group-2-fbbb9fda-dc9f-44c4-b438-ef9ca5df34b0 with group instance id None; client reason: need to re-join with the given member-id: consumer-camel-quarkus-group-2-fbbb9fda-dc9f-44c4-b438-ef9ca5df34b0) (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,605] INFO [GroupCoordinator 1]: Stabilized group camel-quarkus-group generation 1 (__consumer_offsets-29) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:08,685] INFO [GroupCoordinator 1]: Assignment received from leader consumer-camel-quarkus-group-2-fbbb9fda-dc9f-44c4-b438-ef9ca5df34b0 for group camel-quarkus-group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:09,192] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group eac2dbb5-4d9b-4b91-9440-bd5958eea6aa in Empty state. Created a new member id consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1-76e744d6-4887-4a01-8026-4ecb940e1a6c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:09,194] INFO [GroupCoordinator 1]: Preparing to rebalance group eac2dbb5-4d9b-4b91-9440-bd5958eea6aa in state PreparingRebalance with old generation 0 (__consumer_offsets-30) (reason: Adding new member consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1-76e744d6-4887-4a01-8026-4ecb940e1a6c with group instance id None; client reason: need to re-join with the given member-id: consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1-76e744d6-4887-4a01-8026-4ecb940e1a6c) (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:09,195] INFO [GroupCoordinator 1]: Stabilized group eac2dbb5-4d9b-4b91-9440-bd5958eea6aa generation 1 (__consumer_offsets-30) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:09,197] INFO [GroupCoordinator 1]: Assignment received from leader consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1-76e744d6-4887-4a01-8026-4ecb940e1a6c for group eac2dbb5-4d9b-4b91-9440-bd5958eea6aa for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
2024-05-10 11:34:09,234 INFO  [kafka] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) Exchange[ExchangePattern: InOnly, BodyType: String, Body: 8a1be750-4d75-4f00-95b9-1fbd3dc8dc65]
[2024-05-10 09:34:09,280] INFO [GroupCoordinator 1]: Preparing to rebalance group camel-quarkus-group in state PreparingRebalance with old generation 1 (__consumer_offsets-29) (reason: Removing member consumer-camel-quarkus-group-2-fbbb9fda-dc9f-44c4-b438-ef9ca5df34b0 on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:09,280] INFO [GroupCoordinator 1]: Group camel-quarkus-group with generation 2 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:09,282] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-camel-quarkus-group-2-fbbb9fda-dc9f-44c4-b438-ef9ca5df34b0, groupInstanceId=None, clientId=consumer-camel-quarkus-group-2, clientHost=/192.168.32.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group camel-quarkus-group through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.25 s -- in org.apache.camel.quarkus.kafka.ssl.KafkaSslTest
2024-05-10 11:34:10,183 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.5.0 (camel-1) is shutting down (timeout:45s)
2024-05-10 11:34:10,235 INFO  [org.apa.cam.com.kaf.KafkaConsumer] (Camel (camel-1) thread #3 - ShutdownTask) Pausing Kafka record fetcher task running client ID
2024-05-10 11:34:10,236 INFO  [org.apa.cam.com.kaf.KafkaFetchRecords] (Camel (camel-1) thread #3 - ShutdownTask) A pause request was issued and the consumer thread will pause after current processing has finished
2024-05-10 11:34:10,237 INFO  [org.apa.cam.com.kaf.KafkaConsumer] (Camel (camel-1) thread #3 - ShutdownTask) Stopping Kafka consumer on topic: inbound
2024-05-10 11:34:10,237 INFO  [org.apa.cam.com.kaf.KafkaFetchRecords] (Camel (camel-1) thread #3 - ShutdownTask) Waiting up to 30000 milliseconds for the processing to finish
2024-05-10 11:34:14,261 INFO  [org.apa.cam.com.kaf.KafkaFetchRecords] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) Pausing the consumer as a response to a pause request
2024-05-10 11:34:14,262 INFO  [org.apa.cam.com.kaf.KafkaFetchRecords] (Camel (camel-1) thread #1 - KafkaConsumer[inbound]) Terminating KafkaConsumer thread inbound-Thread 0 receiving from topic inbound
[2024-05-10 09:34:14,262] INFO [GroupCoordinator 1]: Preparing to rebalance group eac2dbb5-4d9b-4b91-9440-bd5958eea6aa in state PreparingRebalance with old generation 1 (__consumer_offsets-30) (reason: Removing member consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1-76e744d6-4887-4a01-8026-4ecb940e1a6c on LeaveGroup; client reason: the consumer unsubscribed from all topics) (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:14,263] INFO [GroupCoordinator 1]: Group eac2dbb5-4d9b-4b91-9440-bd5958eea6aa with generation 2 is now empty (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[2024-05-10 09:34:14,264] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1-76e744d6-4887-4a01-8026-4ecb940e1a6c, groupInstanceId=None, clientId=consumer-eac2dbb5-4d9b-4b91-9440-bd5958eea6aa-1, clientHost=/192.168.32.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) has left group eac2dbb5-4d9b-4b91-9440-bd5958eea6aa through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics (kafka.coordinator.group.GroupCoordinator)
2024-05-10 11:34:14,286 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Routes stopped (total:1)
2024-05-10 11:34:14,286 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main)     Stopped route1 (kafka://inbound)
2024-05-10 11:34:14,289 INFO  [org.apa.cam.imp.eng.AbstractCamelContext] (main) Apache Camel 4.5.0 (camel-1) shutdown in 4s106ms (uptime:8s)
2024-05-10 11:34:14,303 INFO  [io.quarkus] (main) camel-quarkus-integration-test-kafka-ssl stopped in 4.129s
[INFO]
[INFO] Results:
[INFO]
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  31.392 s
[INFO] Finished at: 2024-05-10T11:34:14+02:00
[INFO] ------------------------------------------------------------------------
[WARNING]
[WARNING] Plugin validation issues were detected in 1 plugin(s)
[WARNING]
[WARNING]  * org.apache.maven.plugins:maven-enforcer-plugin:3.0.0-M3
[WARNING]
[WARNING] For more or less details, use 'maven.plugin.validation' property with one of the values (case insensitive): [BRIEF, DEFAULT, VERBOSE]
[WARNING]
[jondruse@fedora]~/git/community/camel-quarkus%
